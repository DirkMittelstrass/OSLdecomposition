---
title: "Data set decomposer for RLuminescence"
output: html_notebook
---



```{r setup, include=FALSE}
#Script.date <- "2020-03-06"
#Time.needed <- Sys.time()

library(Luminescence)
library(numOSL)
library(knitr)
library(ggplot2)
library(gridExtra)
library(ggpubr)
library(OSLdecomposition)

# fig.width=6,
knitr::opts_chunk$set(fig.width=7,
                      fig.asp=.4,
                      results = "asis",
                      warning=FALSE,
                      message=FALSE,
                      error=FALSE,
                      echo=FALSE,
                      cache=FALSE)

# fig.align="center",  

```

```{r}
#path <- file.choose()

path <- "C:\\Users\\mitte\\Desktop\\OSL decomposition\\application\\BT1713\\BT1713_SAR_classic.bin"
```
<br> | 
------------------|----------------
Data set  | `r basename(path)`  
Script executed at | `r Sys.time()`  

**Preface**  
This report was automatically generated using the `Rmarkdown` (see Xie *et al.* 2018) script `EvaluateDataSet.Rmd` in the **R** package `OSLdecomposition` written and maintained by Dirk Mittelstraß (<dirk.mittelstrass@luminescence.de>). The dose calculation deploys also functions of the R packages `numOSL` introduced by Jun Peng *et al.* (2013) and `Luminescence` introduced by Sebastian Kreutzer *et al.*(2012)

This report and the containing results can be used, shared and published by the data set maintainer at will. If the results are published, however, it is demanded to state the main **R** package `OSLdecomposition` including its version number (`r packageVersion("OSLdecomposition")`). It is also recommended to add this report to the supplement of your publication.   

A full description of the method and the algorithms involved, as well as some performance tests, can be found in the master thesis this script is based upon:

-------------------

*D. Mittelstraß, ‘Decomposition of weak optically stimulated luminescence signals and its application in retrospective dosimetry at quartz’, Master thesis, TU Dresden, Dresden, 2019.*

-------------------


\pagebreak

## Basic idea
The method is based on the assumption, that every OSL curve can be described as sum of signal components (Bailey *et al.* 1997). It is further assumed, that each signal component can be described by an exponential decay following first order kinetics. The shape of every CW-OSL curve can then be modelled by:  

$$I(t) = \sum_{i = 1}^{K} n_i\lambda_i\exp{(-\lambda_it)}$$

Here, *I(t)* represents the luminescence signal during continuous stimulation, *K* the number signal components, *n~i~* the integrated signal intensities (or just ‘signal values’) of each signal component and $\lambda_i$ their decay constants.
We also assume, that the set of decay constants is the same for all OSL curves in a given data set. So we can apply the following data analysis approach:  

-------------------

1. Determine the component number *K* and the decay parameters $\lambda_i$, …, $\lambda_K$ globally by multi-exponential decay fitting at one representative superposition OSL curve
2. Determine the signal values *n~1~*, …, *n~K~* for each OSL curve by a decomposition algorithm
3. Determine the natural dose signal component-wise by building separate signal-dose growth curves for each set of *n~i~* values

-------------------

\pagebreak

## Script & data parameter

**Script conditions** | 
------------------|----------------
Script version | `r Script.date`
R version | `r packageVersion("base")`
Packages performing calculations | OSLdecomposition `r packageVersion("OSLdecomposition")`
<br> | Luminescence `r packageVersion("Luminescence")`
<br> | numOSL `r packageVersion("numOSL")`

```{r start_parameters, include=FALSE}
# read BIN file:
lum_data <- read_BIN2R(path, 
                       fastForward = TRUE,
                       txtProgressBar = FALSE)

N.raw <- length(lum_data)

# Data set dependend parameters
record_type <- "OSL"

#drop_selection <-c(1:4)  c(22)
drop_selection <- NULL
drop_selection_text <- "none"
if (!is.null(drop_selection)) drop_selection_text <- paste(drop_selection, collapse = ",")

background_selection <- NULL
background_selection_text <- "none"
if (!is.null(background_selection)) background_selection_text <- paste(background_selection, collapse = ",")

lum_data[drop_selection] <- NULL

example_aliquot <- 1
n.table <- 1
n.figure <- 1

first_aliquot <- lum_data[[1]][[record_type]]
N.aliquots <- length(lum_data) - length(background_selection)
```

The data set is imported to **R** by the function `Luminescence::read_BIN2R()` programmed by Kreutzer and Fuchs (2019). Files in the BIN and the BINX format produced by Risoe DA15, Risoe DA20, lexsyg research and lexsyg smart TL/OSL readers are supported.


**Data set conditions** | 
------------------|----------------
Evaluated record types | `r record_type` 
Data set entries (aliquots) | `r N.raw` 
Indicies of dismissed aliquots | `r drop_selection_text`  
Indicies of background measurements | `r background_selection_text`  
Analyzed aliquots | `r N.aliquots`  
`r record_type` records per entry | `r length(first_aliquot)`
Channels | *N* = `r length(first_aliquot[[1]]@data[,1])`
Channel width | $\Delta t$ = `r formatC(first_aliquot[[1]]@data[1,1], digits = 2)` s
Measurement time | *t~end~* = `r formatC(max(first_aliquot[[1]]@data[,1]), digits = 2)`  
  
```{r curves}
#, fig.cap="Figure `1`: Global mean curve (blue); Data points of all OSL curves (grey opaque); First OSL record of first aliquot (red)."

# calc arithmetic mean curve
global_curve <- sum_OSLcurves(lum_data,
                            record_type = record_type,
                            output.plot = TRUE,
                            plot.first = TRUE,
                            plot.global = FALSE,
                            title = NULL,
                            verbose = FALSE)

cat(paste0("<pre>*Figure ", n.figure,": Raw data points of all OSL curves (grey opaque) and natural dose OSL curve of first aliquot (red)*"))
n.figure <- n.figure + 1
```

\pagebreak

```{r start_parameters2}

sample_type <- "fine grain quartz"
single_grain <- FALSE

expected_value <- NA # ka or Gy if age_rate = 1
applied_predose <- 0 # same unit as expected
expected_unit <- "Gy"
  
# values from Maggis Sibirian data sets
# dose_rate <- 4.95 / 60 # Gy/s
#dose_unit <- "Gy" # "s" if dose_rate = 1
#age_rate <- 0.635 # ka/Gy
age_rate <- NA
  
# Dosisleistung lexsyg bayreuth am 18.06.19 
# Grobkorn: 0.0525 ± 0.0028 Gy/s
# Feinkorn: 0.0563 ± 0.0022 Gy/s
dose_rate <- 0.0563 # Gy/s

# dose_rate <- 1 # Gy/s
dose_unit <- "Gy" # "s" if dose_rate = 1
#age_rate <- NA # ka/Gy

# Stimulation parameters
stimulation_wavelength <- 470 
stimulation_intensity <- 30  # mW cm^-2

# Algorithm parameters
cut_time <- 40
max_components <- 3
F_threshold <- 50
algorithm <- "det+nls"

### some minor things ###
if (expected_unit == "s") {
  
  expected_dose <- dose_rate * expected_value
  applied_predose <- dose_rate * applied_predose
  expected_age <- age_rate * expected_dose
  
} else if (expected_unit == "Gy") {
  
  expected_dose <- expected_value
  expected_age <- age_rate * expected_dose
  
} else if (expected_unit == "ka") {
  
  expected_dose <- expected_value / age_rate
  expected_age <- expected_value
}

if (is.finite(expected_dose)) {
  digits_DE <- 2 - round(log10(expected_dose))
} else { digits_DE <- 1 } 

```

**Sample conditions** | 
------------------|----------------
Sample type | `r sample_type`
Expected age | ~ `r expected_age` ka
Environmental dose rate | `r round(1/age_rate, digits = 2)` Gy ka^-1^
Expected dose | ~ `r round(expected_dose, digits = digits_DE)` Gy
Laboratory dose rate | `r round(dose_rate, digits = 4)` Gy s^-1^
Stimulation wavelength | `r stimulation_wavelength` nm
Assumed stimulation intensity | `r stimulation_intensity` mW cm^-2^


**Algorithm settings** | 
-----------------------|----------------
Cut measurements if exceeding | *t~max~* = `r cut_time` s
Maximum allowed components |*K~max~* =  `r max_components`
Threshold *F*-value | *F~threshold~* = `r F_threshold`
Decomposition algorithm | `r algorithm`
Growth curve fitting algorithm | `r fit_method`
Allowed recuperation | `r recuperation_rate*100`%
Allowed recycl. ratio deviation | `r recycling_ratio*100`%

## Data pre-treatment

Prior data evaluation, the records will be corrected for signal background, measurement over-length, etc., depending on the script settings and the provided data. The following corrections were performed by applying the function `prepare_OSLdata()`:  

```{r prepare}
applied_time_cut <- FALSE

# alter the data
# ToDo:
# - background substraction
# - single grain measurement cut
if (max(global_curve$time) > cut_time) {
  
  cat(paste0("* The measurement duration of ", prettyNum(max(global_curve$time)) , 
             " s exceed the preset cut time of ", cut_time, 
             " s. Because long measurements may lead to over-fitting and imprecise fast-decaying component fitting, all records are reduced to the cut time."))
  
  # cut records
  lum_data <- prepare_OSLdata(lum_data, 
                            record.type = record_type,
                            cut.time = cut_time)
  
  applied_time_cut <- TRUE
}

if (!is.null(background_selection)) {
  
  cat(paste0("* Aliquot ", background_selection_text, 
             " is set as background measurement. All OSL records are combined to a mean curve. This mean curve is subtracted from all other records of the data set."))
  
  # cut records
  lum_data <- prepare_OSLdata(lum_data, 
                            record.type = record_type,
                            background.aliquot = background_selection,
                            background.plot = TRUE)
  cat(paste0("<pre>*Figure ", n.figure,": Mean curve of background measurements (blue) and data points of all background measurement (black)*"))
n.figure <- n.figure + 1

}

if (single_grain) {

  
  
  # cut records
  lum_data <- prepare_OSLdata(lum_data, 
                            record.type = record_type,
                            tailor.single.grain = TRUE)
}


```


\pagebreak
## Step 1 – Evaluation of component number and decay constants

For calculating the decay parameters, one representative OSL curve is needed. This is provided by combining all records to one global mean curve. Each data point of the global curve represents the arithmetic mean of all data point values of the same channel in all OSL curves. This increases the signal-to-noise ratio by about one to two orders of magnitude, but still maintains the decay parameter information.  

```{r step1_sum_curves}

# calc arithmetic mean curve, again
global_curve <- sum_OSLcurves(lum_data,
                            record_type = record_type,
                            output.plot = TRUE,
                            plot.first = FALSE,
                            plot.global = TRUE,
                            title = NULL,
                            verbose = FALSE)

cat(paste0("<pre>*Figure ", n.figure,": Global mean ", record_type, " curve (blue) and data points of all OSL records (grey opaque)*"))
n.figure <- n.figure + 1

```

We take the global mean curve and perform a multiple cycles of multi-exponential nonlinear regression. In each cycle, the number of components *K* increases by one. With increasing number of components, decreases the signal deviation (residual curve) between the fitted model curve and the measured data and the fit gets better. 

The underlying algorithm was proposed and described by Bluszcz & Adamiec (2006) and realized in **R** by the function `numOSL::decomp()` by Peng *et al.* (2013). Their function is used in `fit_OSLcurve()`, which calculated the following series of fittings, displayed with `plot_OSLcurve()`:

```{r step1_fit}

# find components via fitting and F-statistics
C.list <- fit_OSLcurve(global_curve,
                       K.max = max_components,
                       F.threshold = F_threshold,
                       stimulation.intensity = stimulation_intensity,
                       stimulation.wavelength = stimulation_wavelength,
                       applied.time.cut = applied_time_cut,
                       background.fitting = FALSE,
                       verbose = FALSE,
                       output.plot = FALSE)

K.selected <- C.list$K.selected
```

\pagebreak

The subsequent diagrams are structured the following way:

* Upper left: Global mean curve (grey), fit model curve (black) and component signals
* Upper right: Same as log-log diagram
* Lower left: Residual curve between fit and global mean curve
* Lower right: Result table with estimated type of component names (colored)


