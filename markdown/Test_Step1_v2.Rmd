---
title: "Step 1 perfomance tests"
date: 2019-08-01
output: html_notebook
---

```{r global_stuff, include=FALSE}

# TODO
# - 

library(Luminescence)
library(numOSL)
library(OSLdecomposition)
library(knitr)
knitr::opts_chunk$set(fig.width=10, fig.asp=.6, warning=FALSE, error=FALSE, echo=FALSE)

# alternative simulations:

V.list <- list(n.Fast = c(0, 1000, 3000, 10000),
               n.Medium = c(0, 1000, 3000),
               n.Slow1 = c(0, 3000, 10000),
               n.Slow2 = c(10000, 30000, 100000),
               Background = c(0),
               Channels = c(100, 200, 400),
               Channel.width = c(0.1, 0.2, 0.5),
               Additions = c(500),
               Chi.weight = c(FALSE),
               Algorithm = c("DEoptim","numOSL","minpack.lm"))

```


1. Build List with vectors which shall be varied


```{r}

# ToDo, use more accurate lambda values
lambda <- c(Fast = 2, Medium = 0.5, Slow1 = 0.1, Slow2 = 0.02)
X <- 1:length(lambda)

V.list <- list(n.Fast = c(0, 5000),
               n.Medium = c(3000),
               n.Slow1 = c(0, 10000),
               n.Slow2 = c(100000),
               Background = c(0),
               Channels = c(200),
               Channel.width = c(0.1),
               Additions = c(500),
               Algorithm = c("numOSL","DE","DE+LM"))
# from earlier simulations, we showed that the impact of uncorrected background signals,
# as well as from the number of additions is insignificant
# it was also shown, that unweighted fitting (Chi² = RSS) leads to more precise
# fast and medium component decay rates

V.max <- NULL

for (i in 1:length(V.list)) {
  V.max <- c(V.max, length(V.list[[i]]))
}

N <- prod(V.max)
cat("Number of scenarios:", N,"\n")

```


2. Cycle through all combinations and build a parameter set for each

```{r}

V.i <- rep(1, length(V.list))
V.table <- data.frame(NULL)

for (j in 1:N) {
  
  V <- NULL
  
  for (i in 1:length(V.list)) {
  
    if(V.i[i] > V.max[i]) {
      V.i[i] <- 1
      V.i[i + 1] <- V.i[i + 1] + 1
    }
    
    V <- c(V, V.list[[i]][V.i[i]])

  }
  
  V.i[1] <- V.i[1] + 1
  
  V.table <- rbind(V.table, V, stringsAsFactors = FALSE)
}

colnames(V.table) <- names(V.list)

```


3. Simulation



```{r}

Sys.time()

C.list <- list(NULL)
Curve <- data.frame(NULL)


for (j in 1:N) {
  
# Select input parameters
  
  V <- V.table[j,]
  C <- data.frame(name = names(V)[X], 
                  lambda = lambda, 
                  n = c(t(V[X])))
  
  C.list[[j]] <- list(NULL)
  C.list[[j]]$input <- C
  C.list[[j]]$parameter <- V
  
  
  
  # Calc global mean OSL curve
  
  for (i in 1:V$Additions) {
    
      Curve.temp <-simulate_OSLcurve(C,
                            channel.width = V$Channel.width,
                            channel.number = V$Channels,
                            add.background = V$Background,
                            add.gaussian.noise = sqrt(V$Background),
                            simulate.curve = TRUE)
      if (i == 1) {
        Curve <- data.frame(time = Curve.temp$time, 
                            signal = Curve.temp$signal)
      } else {
        Curve$signal <- Curve$signal + Curve.temp$signal
      }
  }
  Curve$signal <- Curve$signal / V$Additions

  # Fit global mean OSL curve
 C.fit <- fit_OSLcurve(Curve, 
                       F.threshold = -Inf,
                       verbose = FALSE,
                       output.complex = TRUE)

 C.list[[j]]$output <- C.fit$F.test
}

Sys.time()

```

time comsumption: 2d 6h for 10000 cases (as for 2019-08-03 with Intel core2 duo E7500 @ 2.94 GHz)

4. Rearrange parameters and result data into one big table

```{r}


R.table <- data.frame(NULL)

for (j in 1:N) {

  # How many Components should be there?
  N.comp <- 0
  V.lambda <- lambda
  for (i in X) {
    if (V.table[j,i] > 0) {
      
      N.comp <- N.comp + 1
    } else {
      
      V.lambda[i] <- NA
    }
  }

  Ratio.lambda <- V.lambda
  names(Ratio.lambda) <- paste0("ratio_", names(V.lambda))
  
  Dev.lambda <- V.lambda
  names(Dev.lambda) <- paste0("dev_", names(V.lambda))
  
  
  # seperate results with correct number of components
  F.test <- C.list[[j]]$output
  F.y <- nrow(F.test)
  
  if (F.y >= N.comp) {
    
    # Calc ratio expected and fitted lambdas
    k <- 1
    for (i in X) {
      if (!is.na(V.lambda[i])) {
        
        Ratio.lambda[i] <- F.test[N.comp, k] / V.lambda[i]
        Dev.lambda[i] <- abs(1 - F.test[N.comp, k] / V.lambda[i])
        k <- k + 1
      }
    }
    
    
    if (F.y > N.comp)  {
      F.next <- F.test$F[N.comp + 1]
    } else {
      F.next <- NA
    }
    
    R <- cbind(t(Ratio.lambda),
               t(Dev.lambda),
               data.frame(K = N.comp,
                          Chi2 = F.test$Chi2[N.comp],
                          F = F.test$F[N.comp],
                          F.next = F.next))

    R.table <- rbind(R.table, R)

  } else {
    
    R.table <- rbind(R.table, NA)
  }
}

R.table <- cbind(V.table, R.table)

# delete rows with less components found than expected
R.table <- R.table[!is.na(R.table$F),]
print(nrow(R.table))

# delete background-dominated rows
R.table <- R.table[!((R.table$Channels==400)
                     & (R.table$Channel.width==0.5)
                     & (R.table$Background==40)),]

R.table <- R.table[!((R.table$Channels==400)
                     & (R.table$Channel.width==0.5)
                     & (R.table$Background==20)),]

R.table <- R.table[!((R.table$Channels==400)
                     & (R.table$Channel.width==0.2)
                     & (R.table$Background==40)),]
print(nrow(R.table))

# delete rows with insufficient fit quality
for (i in 1:nrow(R.table)) {
  for (j in 1:3) {
    if (!is.na(R.table[i,13+j]) && (R.table[i,13+j] > 0.1)) {
      R.table[i,]$F <- NA
    }
  }
}
R.table <- R.table[!is.na(R.table$F),]
print(nrow(R.table))
```


5. Create correlation tables and save them for further use in Excel

```{r}
#path <- getwd()
path <- "C:/Users/dm59leto/Desktop"
#C.method <- "kendall"
#C.use <- "complete.obs"

C.table <- cor(R.table, use = "complete.obs", method = "kendall")
write.csv(C.table, paste0(path,"/correlation_table_full.csv"))



C.table <- cor(R.table[R.table$Chi.weight==1,], 
               use = "complete.obs", method = "kendall")
write.csv(C.table, paste0(path,"/correlation_table_Chi_weighted.csv"))



C.table <- cor(R.table[R.table$Chi.weight==0,], 
               use = "complete.obs", method = "kendall")
write.csv(C.table, paste0(path,"/correlation_table_Chi_not_weighted.csv"))



C.table <- cor(R.table[(R.table$Chi.weight==0)
                       & (R.table$Background==20)
                       & (R.table$Additions==500),], 
               use = "complete.obs", method = "kendall")
write.csv(C.table, paste0(path,"/correlation_table_realistic.csv"))



```


6. plot F distributions

```{r, fig.width=12.5, fig.height=5}

library(ggplot2)
library(gridExtra)
theme_set(theme_bw())

  Dlot.1 <- rbind(data.frame(F.value = R.table[R.table$Chi.weight==0,]$F,
                               F.line = factor("same_line")),
                    data.frame(F.value = R.table[R.table$Chi.weight==0,]$F.next,
                               F.line = factor("next_line")))
  
  Dlot.1$F.value <- log10(Dlot.1$F.value)
  
 Plot.1 <- ggplot(Dlot.1, aes(x = F.value, color = F.line)) +
   geom_density(size=1) + ylim(0, 0.7) + 
   scale_x_continuous(limits = c(-2,7), breaks = c(-1,0,1,2,3,4,5,6), 
                   labels = c("0.1","1", "10","100","10^3","10^4","10^5","10^6")) +
   labs(y = "Event Density per Order of 10", x = "F-value") +
   ggtitle("Chi² not weighted") +
   theme(legend.position = "none", 
         axis.title = element_text(size=16),
         axis.text = element_text(size=14),
         plot.title = element_text(size=18, face="bold"))
 
 ###################################################
 
   Dlot.2 <- rbind(data.frame(F.value = R.table[R.table$Chi.weight==1,]$F,
                               F.line = factor("same_line_weighted")),
                    data.frame(F.value = R.table[R.table$Chi.weight==1,]$F.next,
                               F.line = factor("next_line_weighted")))
  
  Dlot.2$F.value <- log10(Dlot.2$F.value)
  
 Plot.2 <- ggplot(Dlot.2, aes(x = F.value, color = F.line)) +
   geom_density(size=1) + ylim(0, 0.7) + 
   scale_x_continuous(limits = c(-2,7), breaks = c(-1,0,1,2,3,4,5,6), 
                   labels = c("0.1","1", "10","100","10^3","10^4","10^5","10^6")) +
   labs(x = "F-value") +
   ggtitle("Chi² weighted") +
   theme(legend.position = "none", 
         axis.title = element_text(size=16), axis.title.y = element_blank(), 
         axis.ticks.y = element_blank(), axis.text.y = element_blank(),
         axis.text.x = element_text(size=14), 
         plot.title = element_text(size=18, face="bold"))
    

 ###################################################
 
 lay <- rbind(c(rep(1,10),rep(2,9)))
 grid.arrange(Plot.1, Plot.2, layout_matrix = lay)
 
 # How many values were used?
 print(paste0("F not weighted: ", nrow(R.table[R.table$Chi.weight==0,])))
 print(paste0("F.next not weighted: ", nrow(R.table[(R.table$Chi.weight==0) & !is.na(R.table$F.next),])))
 print(paste0("F not weighted: ", nrow(R.table[R.table$Chi.weight==1,])))
print(paste0("F.next  weighted: ", nrow(R.table[(R.table$Chi.weight==1) & !is.na(R.table$F.next),])))
```

7. Create new result table

```{r}
F.threshold <- 50

S.table <- data.frame(NULL)

for (j in 1:N) {

  #j <- 1234

  F.test <- C.list[[j]]$output
  F.next <- NA

  # How many Components should be there?
  N.comp <- 0
  V.lambda <- lambda
  for (i in X) {
    if (V.table[j,i] > 0) {
      
      N.comp <- N.comp + 1
    } else {
      
      V.lambda[i] <- NA
    }
  }


  # where falls the F-value below the threshold?
  K.choice <- which(F.test$F < F.threshold)
  
  # select fitting line
  Chosen.by.F <- TRUE
  if (length(K.choice) == 0) {
    
    Chosen.by.F <- FALSE
    K.choice <- nrow(F.test)
  } else {
    
    F.next <- F.test$F[K.choice[1]]
    K.choice <- K.choice[1] - 1
  }
  
  # sort the decay constants to match with the input constants
  S.lambda <-  as.numeric(F.test[K.choice,1:K.choice])
  
  S.matrix <- V.lambda %*% t(1 / S.lambda)
  S.matrix <- abs(S.matrix - 1)
  
  # build a matrix with the correct allocations
  True.matrix <- matrix(rep(FALSE, length(S.matrix)), nrow = nrow(S.matrix), ncol = ncol(S.matrix))
  
  for (i in 1:K.choice) {
    
    True.matrix[which(S.matrix == min(S.matrix[,i], na.rm = TRUE))] <- TRUE
  }
  
  # test if any line has twice TRUE
  for (i in 1:nrow(True.matrix)) {
    if (sum(True.matrix[i,]) > 1) {
      
      A <- which(True.matrix[i,] == TRUE)
      True.matrix[i,] <- FALSE
      True.matrix[which(S.matrix == min(S.matrix[i, A], na.rm = TRUE))[1]] <- TRUE
    }
  }
  
  # put fitted lambdas in relation to input lambdas
  Ratio.lambda <- rep(NA, length(V.lambda))
  names(Ratio.lambda) <- paste0("ratio_", names(V.lambda))
  
  Dev.lambda <- rep(NA, length(V.lambda))
  names(Dev.lambda) <- paste0("dev_", names(V.lambda))
  
  for (i in 1:nrow(True.matrix)) {
    
    if (!(sum(True.matrix[i,]) != 1)) {
          Ratio.lambda[i] <- F.test[K.choice, which(True.matrix[i,] == TRUE)] / V.lambda[i]
      Dev.lambda[i] <- abs(1 - Ratio.lambda[i])
    }
  }
  

  D.lambda <- c(NULL)
  for (i in 1:length(Ratio.lambda)) {
    
    C.missed <- (R.table[j,i] > 0 ) & is.na(Ratio.lambda[i])
    names(C.missed) <- paste0("Missed", substring(names(Ratio.lambda[i]), 6))
    D.lambda <- c(D.lambda, Ratio.lambda[i], Dev.lambda[i], C.missed)
  }
  
    S <- cbind(t(D.lambda),
               data.frame(K.input = N.comp,
                          K.output = K.choice,
                          K.diff = K.choice - N.comp,
                          Chosen.by.F = Chosen.by.F,
                          Chi2 = F.test$Chi2[N.comp],
                          F = F.test$F[N.comp],
                          F.next = F.next))

    S.table <- rbind(S.table, S)
    
}
    
S.table <- cbind(V.table, V.table$Channels * V.table$Channel.width, S.table)
  
```

8.1 Correlation table

```{r}
path <- "C:/Users/mitte/Desktop/Step 1 - correlation tables"

# Correlation table. Warning! Calculation can take several minutes
C.table <- cor(S.table[S.table$Chi.weight == 0,], use = "pairwise.complete.obs", method = "kendall")
write.csv(C.table, paste0(path,"/S.table_correlations_Chi-not-weighted.csv"))
```

8.2 Accuracy table

```{r}
Chi.Weight <- 0

# Accuracy overview table
#Col.selection <- seq(11, 17, 3)
Col.selection <- seq(11, 20, 3)
O.table <- C.table[1:9, Col.selection]
rownames(O.table) <- c("Minimum", "5% percentile", "25% percentile", 
                      "Median", "75% percentile", "95% percentile", "Maximum", "Bandwidth", "Not found")


j <- 1
for (i in Col.selection) {
  
  O.table[1:7,j] <- quantile(S.table[(S.table$Chi.weight==Chi.Weight), i], 
                             probs = c(0, 0.05, 0.25, 0.5, 0.75, 0.95, 1), 
                             na.rm = TRUE)
  
  O.table[8,j] <- nrow(S.table[(S.table$Chi.weight==Chi.Weight) & 
                                 (S.table[,i] < 1.1) & 
                                 (S.table[,i] > 0.9) &
                                 !is.na(S.table[,i]),]) / 
    nrow(S.table[(S.table$Chi.weight==Chi.Weight) & 
    !is.na(S.table[,i]),])
  
  O.table[9,j] <- nrow(S.table[(S.table$Chi.weight==Chi.Weight) & 
                                 (S.table[,j] > 0) & 
                                 is.na(S.table[,i]),]) / 
    nrow(S.table[(S.table$Chi.weight==Chi.Weight) &
                   (S.table[,j] > 0),])
  
  j <- j + 1
}

O.table

#write.csv(C.table, paste0(path,"/S.table_accuracy.csv"))
```

```{r}
library(ggplot2)
library(gridExtra)
```


```{r}
theme_set(theme_bw())

Col.selection <- seq(11, 20, 3)

P.table <- S.table[(S.table$Chi.weight==0), Col.selection]

Plot.table <- data.frame(NULL)

for (i in 1:4) {
  
  A <- P.table[,i]
  A <- na.exclude(A)
  A <- log10(A*lambda[i])
  
  Plot.table <- rbind(Plot.table,
                      
                      data.frame(decay_constant = A, 
                                 component = names(lambda[i])))
}

ggplot(Plot.table, aes(x = decay_constant, colour = component)) + geom_density() + 
  scale_x_reverse()


```



```{r}
K.table <- data.frame(NULL)
for (i in 1:4) {
  
  # Change Chi.weight to select sub-data set
  K.table <- rbind(K.table, 
                   hist(S.table[(S.table$K.input == i) & (S.table$Chi.weight == 0),]$K.output, 
                        breaks = seq(0.5, 5.5, 1), plot=FALSE)$counts)
  
}
colnames(K.table) <- paste0("out=", 1:5)

```

9. Create some box plots

```{r, fig.width=12.5, fig.height=5}

library(ggplot2)
library(gridExtra)
theme_set(theme_bw())

  Dlot.1 <- rbind(data.frame(Lambda.rel = S.table[(S.table$Chi.weight==0) &
                                                    !is.na(S.table$ratio_Fast),]$ratio_Fast,
                               Approach = factor("Chi² not weighted")),
                    data.frame(Lambda.rel = S.table[S.table$Chi.weight==1 &
                                                    !is.na(S.table$ratio_Fast),]$ratio_Fast,
                               Approach = factor("Chi² weighted")))

  
 Plot.1 <- ggplot(Dlot.1, aes(color = Approach, x = Lambda.rel)) +
   geom_density(size=1) + xlim(0.9, 1.1)
   #geom_violin() + ylim(0.95, 1.05)
 

 ###################################################
 
  Dlot.2 <- rbind(data.frame(Lambda.rel = S.table[!is.na(S.table$ratio_Fast),]$ratio_Fast,
                             Chi.weight = S.table[!is.na(S.table$ratio_Fast),]$Chi.weight,
                             Component = factor("Fast")),
                  data.frame(Lambda.rel = S.table[!is.na(S.table$ratio_Medium),]$ratio_Medium,
                             Chi.weight = S.table[!is.na(S.table$ratio_Medium),]$Chi.weight,
                             Component = factor("Medium")),
                  data.frame(Lambda.rel = S.table[!is.na(S.table$ratio_Slow1),]$ratio_Slow1,
                             Chi.weight = S.table[!is.na(S.table$ratio_Slow1),]$Chi.weight,
                             Component = factor("Slow1")),
                  data.frame(Lambda.rel = S.table[!is.na(S.table$ratio_Slow2),]$ratio_Slow2,
                             Chi.weight = S.table[!is.na(S.table$ratio_Slow2),]$Chi.weight,
                             Component = factor("Slow2")))

  
 Plot.2 <- ggplot(Dlot.2, aes(color = Chi.weight, y = Lambda.rel, x = Component)) +
   geom_violin() + scale_y_log10() + ylim(0.5, 2)
#geom_boxplot

 ###################################################
 
 lay <- cbind(1,2)
 grid.arrange(Plot.1, Plot.2, layout_matrix = lay)
 
 # nrow(S.table[(S.table$K.diff < 0) & (S.table$n_Slow1 > 0) & is.na(S.table$ratio_Slow1),]) / nrow(S.table[S.table$K.diff < 0,])

```


