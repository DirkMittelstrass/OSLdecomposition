---
title: "OSL decomposition report *(alpha version)*"
output: word_document
toc: TRUE
toc_depth: 2
---
```{r setup, include=FALSE}
Script.date <- "2019-10-28"
Time.needed <- Sys.time()

library(Luminescence)
library(numOSL)
library(knitr)
library(ggplot2)
library(gridExtra)
library(ggpubr)
library(OSLdecomposition)

# fig.width=6,
knitr::opts_chunk$set(fig.width=7,
                      fig.asp=.4,
                      results = "asis",
                      warning=FALSE,
                      message=FALSE,
                      error=FALSE,
                      echo=FALSE,
                      cache=FALSE)

# fig.align="center",  

```

```{r load_file, include=FALSE}
# path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\Batagai_2-7_B-2-47_OSL_63-100_2mm_Qz1_ed
# path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\Oy7-01-14_63-100_1mm_Qz1-1_ed.BIN"
# path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\BK-8_1295-1280_63-40um_2mm_Qz1_ed.BIN"
# c(1:4)

# SINGLE GRAIN
#path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\C-SAL1_SG_disc2.BIN"
# path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\SUV3_SG_disc1-4.BIN"

# path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\BT1214_all_FKQ_mx.BIN"
# c(22)

# path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\BT594_607_608_612_619.BIN"
# c(25:48) 

# path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\BT1713_SAR_classic.bin"

### DATA SET ###
path <- file.choose()
# path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\BT1713_SAR_classic.bin"
#path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\BT1713_SAR_RT.bin"

# path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\FB_10Gy_SAR_classic.bin"
# path <- "C:\\Users\\mitte\\Desktop\\Masterarbeit\\data\\FB_10Gy_SAR_RT.bin"
# background = c(11)

```
<br> | 
------------------|----------------
Data set  | `r basename(path)`  
Script executed at | `r Sys.time()`  

**Preface**  
This report was automatically generated using the `Rmarkdown` (see Xie *et al.* 2018) script `EvaluateDataSet.Rmd` in the **R** package `OSLdecomposition` written and maintained by Dirk Mittelstraß (<dirk.mittelstrass@luminescence.de>). The dose calculation deploys also functions of the R packages `numOSL` introduced by Jun Peng *et al.* (2013) and `Luminescence` introduced by Sebastian Kreutzer *et al.*(2012)

This report and the containing results can be used, shared and published by the data set maintainer at will. If the results are published, however, it is demanded to state the main **R** package `OSLdecomposition` including its version number (`r packageVersion("OSLdecomposition")`). It is also recommended to add this report to the supplement of your publication.   

A full description of the method and the algorithms involved, as well as some performance tests, can be found in the master thesis this script is based upon:

-------------------

*D. Mittelstraß, ‘Decomposition of weak optically stimulated luminescence signals and its application in retrospective dosimetry at quartz’, Master thesis, TU Dresden, Dresden, 2019.*

-------------------


\pagebreak

## Basic idea
The method is based on the assumption, that every OSL curve can be described as sum of signal components (Bailey *et al.* 1997). It is further assumed, that each signal component can be described by an exponential decay following first order kinetics. The shape of every CW-OSL curve can then be modelled by:  

$$I(t) = \sum_{i = 1}^{K} n_i\lambda_i\exp{(-\lambda_it)}$$

Here, *I(t)* represents the luminescence signal during continuous stimulation, *K* the number signal components, *n~i~* the integrated signal intensities (or just ‘signal values’) of each signal component and $\lambda_i$ their decay constants.
We also assume, that the set of decay constants is the same for all OSL curves in a given data set. So we can apply the following data analysis approach:  

-------------------

1. Determine the component number *K* and the decay parameters $\lambda_i$, …, $\lambda_K$ globally by multi-exponential decay fitting at one representative superposition OSL curve
2. Determine the signal values *n~1~*, …, *n~K~* for each OSL curve by a decomposition algorithm
3. Determine the natural dose signal component-wise by building separate signal-dose growth curves for each set of *n~i~* values

-------------------

\pagebreak

## Script & data parameter

**Script conditions** | 
------------------|----------------
Script version | `r Script.date`
R version | `r packageVersion("base")`
Packages performing calculations | OSLdecomposition `r packageVersion("OSLdecomposition")`
<br> | Luminescence `r packageVersion("Luminescence")`
<br> | numOSL `r packageVersion("numOSL")`

```{r start_parameters, include=FALSE}
# read BIN file:
lum_data <- read_BIN2R(path, 
                       fastForward = TRUE,
                       txtProgressBar = FALSE)

N.raw <- length(lum_data)

# Data set dependend parameters
record_type <- "OSL"

#drop_selection <-c(1:4)  c(22)
drop_selection <- NULL
drop_selection_text <- "none"
if (!is.null(drop_selection)) drop_selection_text <- paste(drop_selection, collapse = ",")

background_selection <- NULL
background_selection_text <- "none"
if (!is.null(background_selection)) background_selection_text <- paste(background_selection, collapse = ",")

lum_data[drop_selection] <- NULL

example_aliquot <- 1
n.table <- 1
n.figure <- 1

first_aliquot <- lum_data[[1]][[record_type]]
N.aliquots <- length(lum_data) - length(background_selection)
```

The data set is imported to **R** by the function `Luminescence::read_BIN2R()` programmed by Kreutzer and Fuchs (2019). Files in the BIN and the BINX format produced by Risoe DA15, Risoe DA20, lexsyg research and lexsyg smart TL/OSL readers are supported.


**Data set conditions** | 
------------------|----------------
Evaluated record types | `r record_type` 
Data set entries (aliquots) | `r N.raw` 
Indicies of dismissed aliquots | `r drop_selection_text`  
Indicies of background measurements | `r background_selection_text`  
Analyzed aliquots | `r N.aliquots`  
`r record_type` records per entry | `r length(first_aliquot)`
Channels | *N* = `r length(first_aliquot[[1]]@data[,1])`
Channel width | $\Delta t$ = `r formatC(first_aliquot[[1]]@data[1,1], digits = 2)` s
Measurement time | *t~end~* = `r formatC(max(first_aliquot[[1]]@data[,1]), digits = 2)`  
  
```{r curves}
#, fig.cap="Figure `1`: Global mean curve (blue); Data points of all OSL curves (grey opaque); First OSL record of first aliquot (red)."

# calc arithmetic mean curve
global_curve <- sum_OSLcurves(lum_data,
                            record_type = record_type,
                            output.plot = TRUE,
                            plot.first = TRUE,
                            plot.global = FALSE,
                            title = NULL,
                            verbose = FALSE)

cat(paste0("<pre>*Figure ", n.figure,": Raw data points of all OSL curves (grey opaque) and natural dose OSL curve of first aliquot (red)*"))
n.figure <- n.figure + 1
```

\pagebreak

```{r start_parameters2}

sample_type <- "fine grain quartz"
single_grain <- FALSE

expected_value <- NA # ka or Gy if age_rate = 1
applied_predose <- 0 # same unit as expected
expected_unit <- "Gy"
  
# values from Maggis Sibirian data sets
# dose_rate <- 4.95 / 60 # Gy/s
#dose_unit <- "Gy" # "s" if dose_rate = 1
#age_rate <- 0.635 # ka/Gy
age_rate <- NA
  
# Dosisleistung lexsyg bayreuth am 18.06.19 
# Grobkorn: 0.0525 ± 0.0028 Gy/s
# Feinkorn: 0.0563 ± 0.0022 Gy/s
dose_rate <- 0.0563 # Gy/s

# dose_rate <- 1 # Gy/s
dose_unit <- "Gy" # "s" if dose_rate = 1
#age_rate <- NA # ka/Gy

# Stimulation parameters
stimulation_wavelength <- 470 
stimulation_intensity <- 30  # mW cm^-2

# Algorithm parameters
cut_time <- 40
max_components <- 5
F_threshold <- 50
algorithm <- "det+nls"
fit_method <- "EXP"
recuperation_rate <- 0.05
recycling_ratio <- 0.1


### some minor things ###
if (expected_unit == "s") {
  
  expected_dose <- dose_rate * expected_value
  applied_predose <- dose_rate * applied_predose
  expected_age <- age_rate * expected_dose
  
} else if (expected_unit == "Gy") {
  
  expected_dose <- expected_value
  expected_age <- age_rate * expected_dose
  
} else if (expected_unit == "ka") {
  
  expected_dose <- expected_value / age_rate
  expected_age <- expected_value
}

if (is.finite(expected_dose)) {
  digits_DE <- 2 - round(log10(expected_dose))
} else { digits_DE <- 1 } 

```

**Sample conditions** | 
------------------|----------------
Sample type | `r sample_type`
Expected age | ~ `r expected_age` ka
Environmental dose rate | `r round(1/age_rate, digits = 2)` Gy ka^-1^
Expected dose | ~ `r round(expected_dose, digits = digits_DE)` Gy
Laboratory dose rate | `r round(dose_rate, digits = 4)` Gy s^-1^
Stimulation wavelength | `r stimulation_wavelength` nm
Assumed stimulation intensity | `r stimulation_intensity` mW cm^-2^


**Algorithm settings** | 
-----------------------|----------------
Cut measurements if exceeding | *t~max~* = `r cut_time` s
Maximum allowed components |*K~max~* =  `r max_components`
Threshold *F*-value | *F~threshold~* = `r F_threshold`
Decomposition algorithm | `r algorithm`
Growth curve fitting algorithm | `r fit_method`
Allowed recuperation | `r recuperation_rate*100`%
Allowed recycl. ratio deviation | `r recycling_ratio*100`%

## Data pre-treatment

Prior data evaluation, the records will be corrected for signal background, measurement over-length, etc., depending on the script settings and the provided data. The following corrections were performed by applying the function `prepare_OSLdata()`:  

```{r prepare}
applied_time_cut <- FALSE

# alter the data
# ToDo:
# - background substraction
# - single grain measurement cut
if (max(global_curve$time) > cut_time) {
  
  cat(paste0("* The measurement duration of ", prettyNum(max(global_curve$time)) , 
             " s exceed the preset cut time of ", cut_time, 
             " s. Because long measurements may lead to over-fitting and imprecise fast-decaying component fitting, all records are reduced to the cut time."))
  
  # cut records
  lum_data <- prepare_OSLdata(lum_data, 
                            record.type = record_type,
                            cut.time = cut_time)
  
  applied_time_cut <- TRUE
}

if (!is.null(background_selection)) {
  
  cat(paste0("* Aliquot ", background_selection_text, 
             " is set as background measurement. All OSL records are combined to a mean curve. This mean curve is subtracted from all other records of the data set."))
  
  # cut records
  lum_data <- prepare_OSLdata(lum_data, 
                            record.type = record_type,
                            background.aliquot = background_selection,
                            background.plot = TRUE)
  cat(paste0("<pre>*Figure ", n.figure,": Mean curve of background measurements (blue) and data points of all background measurement (black)*"))
n.figure <- n.figure + 1

}

if (single_grain) {

  
  
  # cut records
  lum_data <- prepare_OSLdata(lum_data, 
                            record.type = record_type,
                            tailor.single.grain = TRUE)
}




```


\pagebreak
## Step 1 – Evaluation of component number and decay constants

For calculating the decay parameters, one representative OSL curve is needed. This is provided by combining all records to one global mean curve. Each data point of the global curve represents the arithmetic mean of all data point values of the same channel in all OSL curves. This increases the signal-to-noise ratio by about one to two orders of magnitude, but still maintains the decay parameter information.  

```{r step1_sum_curves}

# calc arithmetic mean curve, again
global_curve <- sum_OSLcurves(lum_data,
                            record_type = record_type,
                            output.plot = TRUE,
                            plot.first = FALSE,
                            plot.global = TRUE,
                            title = NULL,
                            verbose = FALSE)

cat(paste0("<pre>*Figure ", n.figure,": Global mean ", record_type, " curve (blue) and data points of all OSL records (grey opaque)*"))
n.figure <- n.figure + 1

```

We take the global mean curve and perform a multiple cycles of multi-exponential nonlinear regression. In each cycle, the number of components *K* increases by one. With increasing number of components, decreases the signal deviation (residual curve) between the fitted model curve and the measured data and the fit gets better. 

The underlying algorithm was proposed and described by Bluszcz & Adamiec (2006) and realized in **R** by the function `numOSL::decomp()` by Peng *et al.* (2013). Their function is used in `fit_OSLcurve()`, which calculated the following series of fittings, displayed with `plot_OSLcurve()`:

```{r step1_fit}

# find components via fitting and F-statistics
C.list <- fit_OSLcurve(global_curve,
                       K.max = max_components,
                       F.threshold = F_threshold,
                       stimulation.intensity = stimulation_intensity,
                       stimulation.wavelength = stimulation_wavelength,
                       applied.time.cut = applied_time_cut,
                       background.fitting = FALSE,
                       verbose = FALSE,
                       output.plot = FALSE)

K.selected <- C.list$K.selected
```

\pagebreak

The subsequent diagrams are structured the following way:

* Upper left: Global mean curve (grey), fit model curve (black) and component signals
* Upper right: Same as log-log diagram
* Lower left: Residual curve between fit and global mean curve
* Lower right: Result table with estimated type of component names (colored)


```{r step1_display_cases, fig.asp=.6}

# display fittings for all K
for (i in 1:nrow(C.list$F.test)) {
  
  plot_OSLcurve(global_curve, 
                C.list$components.list[[i]], 
                title = NULL,
                algorithm = " ")

 # cat(paste0("<pre>**Figure ", n.figure,":** "))
  cat(paste0("<pre>*Figure ", n.figure,": Global mean curve fit with K = ", i, 
             " components* <pre>  ---------  <pre>"))
n.figure <- n.figure + 1

#cat("")
}

```

\pagebreak
**F-test**  
But which of these fittings gives back a sufficient model of the global mean curve, without over-fitting it? We solve this by comparing the residual square sum (*RSS*) of each fitting with the *RSS* value of the previous fitting. Bluszcz & Adamiec (2006) propose to use a *F*-test:  

$$F_K = \frac{(RSS_{K-1} - RSS_K)/2}{RSS_K(N - 2K)} $$


If *F~K~* falls below the preset threshold value of *F~threshold~* = `r F_threshold`, the new fitting model with *K* components is apparently not significantly better than the *K* - 1 model.


```{r F-test_table}
# print F-test table
kable(C.list$F.test.print, 
      escape = TRUE, align = "c",
      caption = "Table 1: Decay constants and fit quality parameters for multi-exponentional decay fitting with *K* components")
```

The fitting with *K* = `r K.selected` components is found to be the best suiting model to describe the given sample. Signal components with not-first-order kinetics, however, can lead to over-fitting. It is recommended to take the results of the *K* = `r K.selected - 1` fitting model also into consideration.  

If the sample was measured with a stimulation light wavelength of about 470 nm and a stimulation light intensity of `r stimulation_intensity` mW cm^-2^ as presetted, the photoionisation cross-sections of the components can be calculated. These can be compared with the quartz LM-OSL findings given in literature.

```{r step1_crosssections, fig.asp = 0.32}

#cross.plot.height <- 0
#if ((stimulation_wavelength >= 465) && (stimulation_wavelength <= 480)) cross.plot.height <- 3
#cross.plot.height <- (cross.plot.height + 2 + K.selected) * 0.01
#knitr::opts_current$set(fig.asp = cross.plot.height)

plot_PhotoCrosssections(C.list,
                        stimulation.intensity = stimulation_intensity,
                        stimulation.wavelength = stimulation_wavelength)

  cat(paste0("<pre>*Figure ", n.figure,": Comparison of decay constants between fitting cases and comparison with reference values. Red square: Best fit*"))
n.figure <- n.figure + 1

```

```{r decompose_SARdata_classic}
SAR.list <- list(NULL)

# Classic late background signal calculation:
components.late <- calc_classicOSLsignal(global_curve, 
                                        algorithm = "late", 
                                        stimulation.intensity = stimulation_intensity,
                                        verbose = FALSE)

SAR.list[[1]] <- decompose_SARdata(lum_data,
                                   components = components.late,
                                   record_type = record_type,
                                   algorithm = "late",
                                   dose.rate = dose_rate,
                                   recuperation_rate = recuperation_rate,
                                   recycling_ratio = recycling_ratio,
                                   applied.pre.dose = applied_predose,
                                   fit.method = fit_method,
                                   verbose = FALSE)

# Classic early background signal calculation:
components.early <- calc_classicOSLsignal(global_curve, 
                                        algorithm = "early", 
                                        stimulation.intensity = stimulation_intensity,
                                        verbose = FALSE)

SAR.list[[2]] <- decompose_SARdata(lum_data,
                                   components = components.early,
                                   record_type = record_type,
                                   algorithm = "early",
                                   dose.rate = dose_rate,
                                   recuperation_rate = recuperation_rate,
                                   recycling_ratio = recycling_ratio,
                                   applied.pre.dose = applied_predose,
                                   fit.method = fit_method,
                                   verbose = FALSE)
```

```{r decompose_SARdata}
# whole-data-set-decomposition for each case of K components:
for (i in 1:K.selected) {
  
SAR.list[[i + 2]] <- decompose_SARdata(lum_data,
                                       components = C.list$components.list[[i]],
                                       record_type = record_type,
                                       algorithm = algorithm,
                                       dose.rate = dose_rate,
                                   recuperation_rate = recuperation_rate,
                                   recycling_ratio = recycling_ratio,
                                       applied.pre.dose = applied_predose,
                                   fit.method = fit_method,
                                       verbose = FALSE)}
```

\pagebreak
## Step 2 – Single curve decomposition

In Step 2, we decompose each OSL curve into its signal components. We set the decay constants found in Step 1 as fixed values for all OSL curves of the data set. This allows us to apply the following signal decomposition method:

-------------------

1. Divide the measurement time into *K* intervals. These intervals are calculated and optimized globally by `calc_OSLintervals()`.
2. Integrate the signal curve of each OSL record over these intervals. From the integration values and the fitting model found in Step 1, build one equation system with *K* equations for each OSL record. 
3. Solve the equation system by an analytic determinant based method, called 'Cramer's rule', and get the area under the component curve or 'intensity' *n~k~* for each signal component
4. To enhance stability and precision of the method, refine the set of *n~k~* values in a quasi-linear regression using `base::nls()`. If this refining-fit fails, go on with the Cramer's rule achieved values.
5. Calculate the standard deviation of the integration values from step 2 by the residuals between fit-model OSL curve and real data points 
6. Apply the propagation of uncertainty method onto Cramer's rule and calculate the uncertainty $\sigma_k$ for each component intensity value *n~k~*

-------------------

All steps, beside the first step, are realized in `decompose_OSLcurve()`. The table in figure `r n.figure` displays the particular outcome of this method for the *K* = `r K.selected` model applied at the first OSL curve of the first aliquot as example. The parameter *tail~n~* gives back the area under the component which is not displayed in the OSL diagram. If the measurement was not cutted in the data-pretreatment and an appropriate background correction was performed, *tail~n~* equals the not-released signal of the component.


```{r step2_first_curve, fig.asp=.6}

example.curve <- lum_data[[example_aliquot]]@records[[SAR.list[[1]]$index[1]]]@data
#example.curve <- lum_data[[1]]@records[[1]]@data
example.components <- decompose_OSLcurve(example.curve,
                                         components = C.list$components.list[[K.selected]],
                                         algorithm = algorithm,
                                         verbose = FALSE)

plot_OSLcurve(example.curve, 
              example.components, 
              title = NULL,
              algorithm = algorithm)

  cat(paste0("<pre>*Figure ", n.figure,": ", K.selected  ,"-component decomposition of the first OSL record in the data set. The vertical lines in the residual diagram show the integration intervals*"))
n.figure <- n.figure + 1

example.LxTx <- SAR.list[[K.selected]][[1]]@data$LnLxTnTx.table[[example_aliquot]]
test_dose <- paste0(formatC(example.LxTx[1,ncol(example.LxTx)], digits = 3), " ", dose_unit)
```

\pagebreak
**L/T table**  
We assume the data set is measured in accordance to the SAR protocol defined by Murray and Wintle (2000). Then every OSL measurement is followed by the regeneration of a fixed test-dose (here `r test_dose`) and the measurement of the OSL signal related to this test-dose. The testdose-related OSL signal is indicated by the variable *T~i~*, the natural and regenerated dose OSL signal is indicated by the variable *L~i~*. The normalized OSL signal is therefore given by $L_i/T_i$.  

A L/T table provides a structure for the signal values and dose regeneration points we need to build dose-signal curves in Step 3 and to test for signal behaviour criteria. One L/T table per signal component and aliquot is built. To avoid some potential issues in Step 3, we apply the following conditions when assigning the signal values to the table:

* If the measurement time was not cutted: Substract the value of *tail~n~* from the *n~k~* value of the subsequent OSL measurement. This enables correctly built L/T tables for slow decaying components.
* If the measurement time was cutted: Do not build L/T tables of a component, when more than 1% of the components signal would be transferred into *tail~n~*. So the component can not be further evaluated and misleading conclusions are avoided.
* Set negative $L_i/T_i$ values to $L_i/T_i = 0$ to avoid calculation issues although negative values are mathematically and physically possible (due to photo-transfer).
  
  
```{r step2_first_LxTx_table}

# re-design table, so it looks nicer
LxTx.table <- example.LxTx[,c(1:5,7:8)]

LxTx.table[,2:3] <- round(LxTx.table[,2:3], digits = 2)
LxTx.table[,4:7] <- round(LxTx.table[,4:7], digits = 0)
LxTx.table[1,1] <- "natural"
LxTx.table <- cbind(data.frame(Cycle = 0:(nrow(LxTx.table) - 1)), LxTx.table)

colnames(LxTx.table) <- c(" *i* ", paste0("dose (", dose_unit ,")"), 
                          "$L_i/T_i$", "$\\sigma_{L_i/T_i}$", 
                          "$L_i$", "$\\sigma_{L_i}$", 
                          "$T_i$", "$\\sigma_{T_i}$")

text.caption <- paste0("Table 2: L/T table of fastest decaying component of first aliquot for the K = ", K.selected ," case. Test dose for generating all T~i~ is: D~T~ = ",test_dose)
kable(LxTx.table, 
      escape = TRUE, align = "c",
      caption = text.caption)

```

\pagebreak
## Step 3 – Equivalent dose calculation

From the L/T table, we create a signal dose curve or "growth curve" by calling the function `Luminescence::plot_GrowthCurve()`programmed by Kreutzer and Dietze (2019). The function plots the luminescence signal values $y = L_i/T_i$ against the regeneration doses *x = D~i~*. Several fitting models are selectable. We will use the default model:

$$y(x) = a (1-e^{-(x+c)/b})$$

Here *a*, *b* and *c* are fitting factors. The natural or 'equivalent' dose *D~e~* related to the natural luminescence signal is calculated by solving $y(D_e) = L_0/T_0$. The uncertainty of the equivalent dose *D~e~* is calculated by a Monte Carlo simulation assuming normal distributed $L_i/T_i$ values with a standard deviation equal to $\sigma_{L_i/T_i}$.  

```{r step3_growth_curve, fig.asp=.8, fig.cap="Figure 4: Growth curve"}

plot_GrowthCurve(example.LxTx, 
                 output.plotExtended = TRUE,
                 fit.method = fit_method,
                 verbose = FALSE,
                 fit.weights = TRUE)

  cat(paste0("<pre>*Figure ", n.figure,": Signal-dose curve of the fastest decaying component of the first aliquot, plotted by `Luminescence::plot_GrowthCurve()`. Lower left: Distribution of Monte Carlo simulatd D~e~ values, used to calculate the D~e~ error value. Lower right: Variation of the normalized Test dose signal over the measurement sequence, useful to display luminescence sensitivity changes.*"))
n.figure <- n.figure + 1
```

\pagebreak
We calculate the equivalent doses *D~e~* for all aliquots and all components for which L/T tables were built. We do this not just for the *K* = `r K.selected` case we selected per *F*-test in Step 1 but also for all *K* < `r K.selected` cases. This way, we gain dose information even if the *K* = `r K.selected` doses aren't sucessfully evaluated due low signal-to-noise ratio or over-fitting in Step 1. 

**Classic signal calculation approaches**  
For comparison, we also calculate *D~e~* values by late light background substraction and early light background substraction. The late light background substraction approach or short 'late background' approach was defined by Murray & Wintle (2000) in their definition of the standard SAR protocol. Here, the function `calc_classisOSLsignal()` performs the signal calculation and sets the integration intervals following the rules by Murray & Wintle (2000). The 'early background' approach introduced by Cunningham and Wallinga (2010) try to remove not-Fast-signal components by substraction the signal directly after the Fast signal decayed.  

For this data set, the following signal and background intervals hat been determined:  

 <br> | Signal interval | Background interval  
------------------------------------|-----------------|---------------------  
Late light background substraction | `r paste0(formatC(components.late$t.start[1], digits = 3), " to ", formatC(components.late$t.end[1], digits = 3)," s")` | `r paste0(formatC(components.late$t.start[2], digits = 3), " to ", formatC(components.late$t.end[2], digits = 3)," s")`  
Early light background substraction | `r paste0(formatC(components.early$t.start[1], digits = 3), " to ", formatC(components.early$t.end[1], digits = 3)," s")` | `r paste0(formatC(components.early$t.start[2], digits = 3), " to ", formatC(components.early$t.end[2], digits = 3)," s")`  
  

\pagebreak

The simplest way to estimate the stored dose information is by calculating the medians of the *D~e~* populations.  

```{r step3_De_medians}

De_medians <- table_SARdata(SAR.list,
                            data.type = "De",
                            criterion = "median",
                            unit = dose_unit,
                            digits = digits_DE,
                            add.number = TRUE,
                            add.number.prefix = "()")

text.caption <- paste0("Table 4: Medians of the D~e~-distributions from ",
                       nrow(SAR.list[[1]][[1]]@data[["data"]]), 
                       " aliquots from different signal calculation approaches. The first line lists the median values of the fastest decaying signal component, the second line the second fastest, etc.. The value inside the brackets () shows the number of sucessful calculated*D~e~'s.")
kable(De_medians, 
      escape = TRUE, align = "c",
      caption = text.caption)
```

Note, that fit failures are common and can happen if the $L_i/T_i$ values have to large errors or don't follow a growth curve or if $L_0/T_0$ is larger than the fit parameter *a*.

Table 4 vizualized in a series of box plots, we get:

```{r step3_dose_plot}

De_medians <- table_SARdata(SAR.list,
              data.type = "De",
              criterion = "median",
              unit = dose_unit,
              expected_value = expected_dose,
              output.plot = TRUE)

  cat(paste0("<pre>*Figure ", n.figure,": Box plots of the *D~e~*-distributions from ",
                       nrow(SAR.list[[1]][[1]]@data[["data"]]), 
                       " aliquots from different signal calculation approaches. The dashed line shows the expected does. Box plot rules: The whiskers enclose all four quartiles besides outlier. The rectangles enclose the second and third quartile. The middle line shows the median*"))
n.figure <- n.figure + 1
```

\pagebreak

## Rejection criteria

The equivalent doses calculated so far, are not necessarily physical meaningful. Murray and Wintle introduced two tests to detect and reject not trustworthy *D~e~* values.  

**Recycling ratio test**  
In the SAR protocol, the first and the last dose regeneration cycle apply usally the same dose (=recycled dose). The generated normalized luminescence signals $L_1/T_1$ and $L_{last}/T_{last}$ should be about equal. If the ratio between both differs significantly from one, it implicates that the applied doses cannt be monitored precisely.


```{r step3_recycling}

recycling <- table_SARdata(SAR.list,
                           data.type = "recycling.ratio",
                           criterion = "mean",
                           digits = 2)

text.caption <- paste0("Table 5: Mean and standard deviation of the recycling ratios from all successfully fitted aliquots")
kable(recycling, 
      escape = TRUE, align = "c",
      caption = text.caption)
```

Be aware, that the recycling ratio calculation is quite noise-sensitive, especially if small test doses are chosen. For low-SNR data sets, false positive as well as false negative aliquot rejections are likely.

**Recuperation test**  
In the regeneration cycle after the cycle with the largest applied dose, usually no dose is applied before measuring *L~i~*. If no dose is applied, the corresponding normalized luminescence signal  $L_i/T_i$ should be about zero. The occurence of significant luminescence signal hints towards the appearance of charge transfer into the observed OSL traps unrelated to dose regeneration.  


```{r step3_recuperation}

recuperation <- table_SARdata(SAR.list,
                               data.type = "recuperation.rate",
                               criterion = "mean",
                           digits = 3)

text.caption <- paste0("Table 6: Mean and standard deviation of the recuperation rates from all successfully fitted aliquots")
kable(recuperation, 
      escape = TRUE, align = "c",
      caption = text.caption)
```


We use the range of acceptance proposed by Murray and Wintle (2000) for both tests:

<br> | Formula | Range of acceptance  
----------------|-----------------|--------------------  
Recycling ratio | $r_{recycling} =  \frac{L_1/T_1}{L_{last}/T_{last}}$ |  $0.9 < r_{recycling} < 1.1$  
Recuperation rate | $r_{recuperation} =  \frac{L_{D_i=0}/T_i}{L_0/T_0}$ |  $r_{recuperation} < 0.05$  

How many aliquots fullfill these criteria?  

```{r step3_rejections}

rejections <- table_SARdata(SAR.list,
                               data.type = "RC.Status",
                               criterion = "number",
                            add.number.prefix = "of",
                            add.number = TRUE)

text.caption <- paste0("Table 7: Number of aliquots which passed rejection criteria successfully.")
kable(rejections, 
      escape = TRUE, align = "c",
      caption = text.caption)
```

Applying the test criteria should reject the majority of inaccurate *D~e~* measurements. How does this change the *D~e~* dose distribution?  

```{r step3_dose_plot_RC}

median.doses <- table_SARdata(SAR.list,
                               data.type = "De",
                               criterion = "median",
                              unit = dose_unit,
                              expected_value = expected_dose,
                              apply.RC = TRUE,
                              output.plot = TRUE)

  cat(paste0("<pre>*Figure ", n.figure,": Box plots of the *D~e~*-distributions from ",
                       nrow(SAR.list[[1]][[1]]@data[["data"]]), 
                       " aliquots which passed the rejection criteria.*  "))
n.figure <- n.figure + 1
```

\pagebreak

## Paleodose and age estimation

We will use two approaches to calculating the burial age from a distribution of equivalent dose values which are common in the geoscientific community: The central age model and the minimum age model. Both models were introduced by Galbraith et al. (1999) and are comprehensibly summarized in Galbraith and Roberts (2012). We will use this step also to transform the dose values into age values, given an environemtal dose rate was given at the beginning of this script.  

**Central age model**  
The central age model (short: 'CAM') proposed by Galbraith et al. (1999) assumes that the logarithmic values of the *D~e~*'s are about normal distributed. But this normal distribution arises not just from measurement errors of the *D~e~*-evaluation but also from unknown geologic or physical uncertainties. The CAM algorithm try to calculate a variance-weighted arithmetic mean from the log(*D~e~*) values but includes an unknown uncertainty parameter in the weigthing term, called 'overdispersion'. The overdispersion $\sigma_b$ is used as second fitting parameter besides the paleodose. In case the *D~e~*-distribution is just caused by instrumental errors, the overdisperion should be around zero. For geologic samples, overdispersions up to $\sigma_b = 0.5$ are common. We calculate the CAM paleodoses using `Luminescence::calc_CentralDose()` programmed by Burow (2019a).  

In a nutshell: The CAM resulting paleodose is a kind of weighted geometric mean of the equivalent doses with an extra property (the overdispersion) indicating the pre-measurement dose uncertainty.  

```{r step3_CAM}

CAM <- table_SARdata(SAR.list,
                     criterion = "CAM",
                     apply.RC = TRUE,
                     add.number = TRUE,
                     digits = digits_DE,
                     unit = dose_unit,
                     age_rate = age_rate)

text.caption <- paste0("Table 8: Central age model obtained paleodoses. In the brackets: overdispersion.")
kable(CAM, 
      escape = TRUE, align = "c",
      caption = text.caption)
```

**Minimum age model**  
The central age model does not take into account that the sample might be bleached incompletely before the burial event. For that case, Galbraith et al. (1999) assume a truncated normal distribution of the *D~e~* values spreaded towards higher doses. The central age model would lead to over-estimated paleodoses, so they added one more fitting parameter to the CAM approach to compensate for the spreading. If the MAM paleodose is significantly lower than the CAM paleodose, incomplete bleaching before burial is likely. We calculate the MAM paleodoses using `Luminescence::calc_CentralDose()` programmed by Burow (2019b).  

```{r step3_MAM}

MAM <- table_SARdata(SAR.list,
                     criterion = "MAM",
                     apply.RC = TRUE,
                     add.number = FALSE,
                     digits = digits_DE,
                     unit = dose_unit,
                     age_rate = age_rate)

text.caption <- paste0("Table 9: Minimum age model obtained paleodoses. \\sigma~b~ = 0.2.")
kable(MAM,
      escape = TRUE, align = "c",
      caption = text.caption)
```

In the MAM algorithm the overdispersion $\sigma_b$ becomes an input parameter. In lack of experimental obtained $\sigma_b$ (a fully bleached sample is needed), we set $\sigma_b = 0.2$ per default, as proposed by Galbraith and Roberts (2012).

\pagebreak

## Summary

Signal-component wise dose evaluation of the file **`r basename(path)`**: 

```{r summary_graph1}

#`r length(first_aliquot) * N.aliquots`
# with **R** package `OSLdecomposition` `r packageVersion("OSLdecomposition")`. 
# calc arithmetic mean curve, again
p1 <- sum_OSLcurves(lum_data,
                            record_type = record_type,
                            output.plot = TRUE,
                            plot.first = TRUE,
                            plot.global = TRUE,
                            title = NULL,
                            verbose = FALSE,
                            return.plot = TRUE)

  p2 <- plot_OSLcurve(global_curve, 
                C.list$components.list[[K.selected]], 
                title = NULL,
                algorithm = " ",
                display = "return.lin")

  grid.arrange(p1, p2, nrow = 1, layout_matrix = cbind(1,2))
  
  cat(paste0("<pre>*Figure ", n.figure,": Left: Data points of whole data set with first curve (red) and global mean curve (blue). Right: Global mean curve (grey) fitted (black) with ", K.selected," components (colored)*"))
n.figure <- n.figure + 1
```
  
```{r summary_graph2, fig.asp=0.3}

plot_PhotoCrosssections(C.list,
                        stimulation.intensity = stimulation_intensity,
                        stimulation.wavelength = stimulation_wavelength)

  cat(paste0("<pre>*Figure ", n.figure,": Evolution of the decay constants with increasing number of components K. Red square: Best fit chosen through F-test*"))
n.figure <- n.figure + 1
```

-------------------------------------  


```{r summary_table}

summary_table <- data.frame(NULL)
for (i in 1:2) {
  summary_line <- data.frame(method = SAR.list[[i]]$table.header,
                             name = "",
                             lambda = "", n = "", 
                             passed.RC = rejections[1, 1 + i],
                             CAM = CAM[1, 1 + i],
                             MAM = MAM[1, 1 + i])
  summary_table <- rbind(summary_table, summary_line)
}

for (i in 5:(K.selected + 2)) {
  
  Selection <- ((CAM[[i + 1]] != "-") & (CAM[[i + 1]] != "")) | 
    ((MAM[[i + 1]] != "-") & (MAM[[i + 1]] != ""))
  for (j in c(1:nrow(CAM))[Selection]) {
    
    #name.text <- paste0("Comp. ", CAM[j, 1], " in ", SAR.list[[i]]$table.header)
    
    lambda <- formatC(as.numeric(C.list$components.list[[i - 2]]$lambda)[j], digits = 2)
    n <- formatC(as.numeric(C.list$components.list[[i - 2]]$n)[j], digits = 2)
    summary_line <- data.frame(method = SAR.list[[i]]$table.header,
                               name = as.character(C.list$components.list[[i - 2]]$name)[j],
                             lambda = paste0(lambda, " $s^{-1}$"), 
                             n = n, 
                             passed.RC = rejections[j, 1 + i],
                             CAM = CAM[j, 1 + i],
                             MAM = MAM[j, 1 + i])
    
      summary_table <- rbind(summary_table, summary_line)
  }
}
colnames(summary_table) <- c("Method", "Component", "Decay constant", "Mean intensity",
                             "Passed aliquots",
                             "Central age model",
                             "Minimum age model")

text.caption <- paste0("Table 10: Result overview. Mean intensity: Area under the signal component curve in the global mean OSL curve. Passed aliquots: How many aliquots with successfully obtained D~e~ value passed the rejection criteria? CAM and MAM use just passed aliquots. CAM: Overdisperion ratio in brackets. MAM: Overdisperion ratio is assumed to be 0.2.  ")
kable(summary_table,
      escape = TRUE, align = "c",
      caption = text.caption)
```

\pagebreak
## References
Bailey 1997 ...  

Bluszcz, A., Adamiec, G., 2006. Application of differential evolution to fitting OSL decay curves. Radiation Measurements 41, 886–891. https://doi.org/10.1016/j.radmeas.2006.05.016  

Burow, C., 2019a. calc_CentralDose(): Apply the central age model (CAM) after Galbraith et al. (1999) to a given De distribution., Luminescence: Comprehensive Luminescence Dating Data Analysis R package version 0.9.5.  

Burow, C., 2019b. calc_MinDose(): Apply the (un-)logged minimum age model (MAM) after Galbraith et al. (1999) to a given De distribution., Luminescence: Comprehensive Luminescence Dating Data Analysis R package version 0.9.5.  

Cunningham, A.C., Wallinga, J., 2010. Selection of integration time intervals for quartz OSL decay curves. Quaternary Geochronology 5, 657–666. https://doi.org/10.1016/j.quageo.2010.08.004  

Durcan, J.A., Duller, G.A.T., 2011. The fast ratio: A rapid measure for testing the dominance of the fast component in the initial OSL signal from quartz. Radiation Measurements 46, 1065–1072. https://doi.org/10.1016/j.radmeas.2011.07.016  

Galbraith, R.F., Roberts, R.G., 2012. Statistical aspects of equivalent dose and error calculation and display in OSL dating: An overview and some recommendations. Quaternary Geochronology 11, 1–27. https://doi.org/10.1016/j.quageo.2012.04.020  

Galbraith, R.F., Roberts, R.G., Laslett, G.M., Yoshida, H., Olley, J.M., 1999. OPTICAL DATING OF SINGLE AND MULTIPLE GRAINS OF QUARTZ FROM JINMIUM ROCK SHELTER, NORTHERN AUSTRALIA: PART I, EXPERIMENTAL DESIGN AND STATISTICAL MODELS. Archaeometry 41, 339–364. https://doi.org/10.1111/j.1475-4754.1999.tb00987.x  

Jain, M., Murray, A.S., Bøtter-Jensen, L., 2003. Characterisation of blue-light stimulated luminescence components in different quartz samples: implications for dose measurement. Radiation Measurements 37, 441–449.  

Kreutzer, S., Burow, C., Fuchs, M., Schmidt, C., Fischer, M., Friedrich, J., 2019. Luminescence: Comprehensive Luminescence Dating Data Analysis. R package.  

Kreutzer, S., Dietze, M., 2019. plot_GrowthCurve(): Fit and plot a growth curve for luminescence data (Lx/Tx against dose)., Luminescence: Comprehensive Luminescence Dating Data Analysis R package version 0.9.5.  

Kreutzer, S., Fuchs, M.C., 2019. read_BIN2R(): Import Risø BIN/BINX-files into R. Function version 0.16.1., Luminescence: Comprehensive Luminescence Dating Data Analysis R package version 0.9.5.  

Kreutzer, S., Schmidt, C., Fuchs, M.C., Dietze, M., Fuchs, M., 2012. Introducing an R package for luminescence dating analysis. Ancient TL 30.  

Murray, A.S., Wintle, A.G., 2000. Luminescence dating of quartz using an improved single-aliquot regenerative-dose protocol. Radiation Measurements 32, 57–73. https://doi.org/10.1016/S1350-4487(99)00253-X  

Peng, J., Dong, Z., Han, F., Long, H., Liu, X., 2013. R package numOSL: numeric routines for optically stimulated luminescence dating. Ancient TL 31.  

Singarayer, J.S., Bailey, R.M., 2004. Component-resolved bleaching spectra of quartz optically stimulated luminescence: preliminary results and implications for dating. Radiation Measurements 38, 111–118. https://doi.org/10.1016/S1350-4487(03)00250-6  

Xie, Y., Allaire, J.J., Grolemund, G., 2018. R Markdown: the definitive guide. Taylor & Francis, CRC Press, Boca Raton.  
  
  
```{r script_finished}

Time.needed <- Sys.time() - Time.needed
print(Time.needed)
#cat(paste0("Time needed to perform this script: ", Time.needed))

```

