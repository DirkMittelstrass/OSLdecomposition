Ratio.lambda <- rep(NA, length(V.lambda))
names(Ratio.lambda) <- paste0("ratio_", names(V.lambda))
Dev.lambda <- rep(NA, length(V.lambda))
names(Dev.lambda) <- paste0("dev_", names(V.lambda))
for (i in 1:nrow(True.matrix)) {
if (!(sum(True.matrix[i,]) != 1)) {
Ratio.lambda[i] <- F.test[K.choice, which(True.matrix[i,] == TRUE)] / V.lambda[i]
Dev.lambda[i] <- abs(1 - Ratio.lambda[i])
}
}
D.lambda <- c(NULL)
for (i in 1:length(Ratio.lambda)) {
C.missed <- (R.table[j,i] > 0 ) & is.na(Ratio.lambda[i])
names(C.missed) <- paste0("Missed", substring(names(Ratio.lambda[i]), 6))
D.lambda <- c(D.lambda, Ratio.lambda[i], Dev.lambda[i], C.missed)
}
S <- cbind(t(D.lambda),
data.frame(K.input = N.comp,
K.output = K.choice,
K.diff = K.choice - N.comp,
Chosen.by.F = Chosen.by.F,
Chi2 = F.test$RSS[N.comp],
F = F.test$F_value[N.comp],
F.next = F.next))
S.table <- rbind(S.table, S)
}
S.table <- cbind(V.table, V.table$Channels * V.table$Channel.width, S.table)
path <- "C:/Users/mitte/Desktop"
# Correlation table. Warning! Calculation can take several minutes
C.table <- cor(S.table[S.table$Algorithm == 3,], use = "pairwise.complete.obs", method = "kendall")
write.csv(C.table, paste0(path,"/S.table_correlations_DE+LM.csv"))
selected_value <- 3
# Accuracy overview table
#Col.selection <- seq(11, 17, 3)
Col.selection <- seq(11, 20, 3)
O.table <- C.table[1:9, Col.selection]
rownames(O.table) <- c("Minimum", "5% percentile", "25% percentile",
"Median", "75% percentile", "95% percentile", "Maximum", "Bandwidth", "Not found")
j <- 1
for (i in Col.selection) {
O.table[1:7,j] <- quantile(S.table[(S.table$Algorithm == selected_value), i],
probs = c(0, 0.05, 0.25, 0.5, 0.75, 0.95, 1),
na.rm = TRUE)
O.table[8,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,i] < 1.1) &
(S.table[,i] > 0.9) &
!is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
!is.na(S.table[,i]),])
O.table[9,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0) &
is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0),])
j <- j + 1
}
O.table
#write.csv(C.table, paste0(path,"/S.table_accuracy.csv"))
selected_value <- 2
# Accuracy overview table
#Col.selection <- seq(11, 17, 3)
Col.selection <- seq(11, 20, 3)
O.table <- C.table[1:9, Col.selection]
rownames(O.table) <- c("Minimum", "5% percentile", "25% percentile",
"Median", "75% percentile", "95% percentile", "Maximum", "Bandwidth", "Not found")
j <- 1
for (i in Col.selection) {
O.table[1:7,j] <- quantile(S.table[(S.table$Algorithm == selected_value), i],
probs = c(0, 0.05, 0.25, 0.5, 0.75, 0.95, 1),
na.rm = TRUE)
O.table[8,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,i] < 1.1) &
(S.table[,i] > 0.9) &
!is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
!is.na(S.table[,i]),])
O.table[9,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0) &
is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0),])
j <- j + 1
}
O.table
#write.csv(C.table, paste0(path,"/S.table_accuracy.csv"))
selected_value <- 3
# Accuracy overview table
#Col.selection <- seq(11, 17, 3)
Col.selection <- seq(11, 20, 3)
O.table <- C.table[1:9, Col.selection]
rownames(O.table) <- c("Minimum", "5% percentile", "25% percentile",
"Median", "75% percentile", "95% percentile", "Maximum", "Bandwidth", "Not found")
j <- 1
for (i in Col.selection) {
O.table[1:7,j] <- quantile(S.table[(S.table$Algorithm == selected_value), i],
probs = c(0, 0.05, 0.25, 0.5, 0.75, 0.95, 1),
na.rm = TRUE)
O.table[8,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,i] < 1.1) &
(S.table[,i] > 0.9) &
!is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
!is.na(S.table[,i]),])
O.table[9,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0) &
is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0),])
j <- j + 1
}
O.table
#write.csv(C.table, paste0(path,"/S.table_accuracy.csv"))
selected_value <- 1
# Accuracy overview table
#Col.selection <- seq(11, 17, 3)
Col.selection <- seq(11, 20, 3)
O.table <- C.table[1:9, Col.selection]
rownames(O.table) <- c("Minimum", "5% percentile", "25% percentile",
"Median", "75% percentile", "95% percentile", "Maximum", "Bandwidth", "Not found")
j <- 1
for (i in Col.selection) {
O.table[1:7,j] <- quantile(S.table[(S.table$Algorithm == selected_value), i],
probs = c(0, 0.05, 0.25, 0.5, 0.75, 0.95, 1),
na.rm = TRUE)
O.table[8,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,i] < 1.1) &
(S.table[,i] > 0.9) &
!is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
!is.na(S.table[,i]),])
O.table[9,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0) &
is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0),])
j <- j + 1
}
O.table
#write.csv(C.table, paste0(path,"/S.table_accuracy.csv"))
F.threshold <- 150
S.table <- data.frame(NULL)
for (j in 1:N) {
#j <- 1234
F.test <- C.list[[j]]$output
F.next <- NA
# How many Components should be there?
N.comp <- 0
V.lambda <- lambda
for (i in X) {
if (V.table[j,i] > 0) {
N.comp <- N.comp + 1
} else {
V.lambda[i] <- NA
}
}
# where falls the F-value below the threshold?
K.choice <- which(F.test$F_value < F.threshold)
# select fitting line
Chosen.by.F <- TRUE
if (length(K.choice) == 0) {
Chosen.by.F <- FALSE
K.choice <- nrow(F.test)
} else {
F.next <- F.test$F_value[K.choice[1]]
K.choice <- K.choice[1] - 1
}
# sort the decay constants to match with the input constants
S.lambda <-  as.numeric(F.test[K.choice,1:K.choice])
S.matrix <- V.lambda %*% t(1 / S.lambda)
S.matrix <- abs(S.matrix - 1)
# build a matrix with the correct allocations
True.matrix <- matrix(rep(FALSE, length(S.matrix)), nrow = nrow(S.matrix), ncol = ncol(S.matrix))
for (i in 1:K.choice) {
True.matrix[which(S.matrix == min(S.matrix[,i], na.rm = TRUE))] <- TRUE
}
# test if any line has twice TRUE
for (i in 1:nrow(True.matrix)) {
if (sum(True.matrix[i,]) > 1) {
A <- which(True.matrix[i,] == TRUE)
True.matrix[i,] <- FALSE
True.matrix[which(S.matrix == min(S.matrix[i, A], na.rm = TRUE))[1]] <- TRUE
}
}
# put fitted lambdas in relation to input lambdas
Ratio.lambda <- rep(NA, length(V.lambda))
names(Ratio.lambda) <- paste0("ratio_", names(V.lambda))
Dev.lambda <- rep(NA, length(V.lambda))
names(Dev.lambda) <- paste0("dev_", names(V.lambda))
for (i in 1:nrow(True.matrix)) {
if (!(sum(True.matrix[i,]) != 1)) {
Ratio.lambda[i] <- F.test[K.choice, which(True.matrix[i,] == TRUE)] / V.lambda[i]
Dev.lambda[i] <- abs(1 - Ratio.lambda[i])
}
}
D.lambda <- c(NULL)
for (i in 1:length(Ratio.lambda)) {
C.missed <- (R.table[j,i] > 0 ) & is.na(Ratio.lambda[i])
names(C.missed) <- paste0("Missed", substring(names(Ratio.lambda[i]), 6))
D.lambda <- c(D.lambda, Ratio.lambda[i], Dev.lambda[i], C.missed)
}
S <- cbind(t(D.lambda),
data.frame(K.input = N.comp,
K.output = K.choice,
K.diff = K.choice - N.comp,
Chosen.by.F = Chosen.by.F,
Chi2 = F.test$RSS[N.comp],
F = F.test$F_value[N.comp],
F.next = F.next))
S.table <- rbind(S.table, S)
}
S.table <- cbind(V.table, V.table$Channels * V.table$Channel.width, S.table)
path <- "C:/Users/mitte/Desktop"
# Correlation table. Warning! Calculation can take several minutes
C.table <- cor(S.table[S.table$Algorithm == 3,], use = "pairwise.complete.obs", method = "kendall")
write.csv(C.table, paste0(path,"/S.table_correlations_DE+LM.csv"))
selected_value <- 1
# Accuracy overview table
#Col.selection <- seq(11, 17, 3)
Col.selection <- seq(11, 20, 3)
O.table <- C.table[1:9, Col.selection]
rownames(O.table) <- c("Minimum", "5% percentile", "25% percentile",
"Median", "75% percentile", "95% percentile", "Maximum", "Bandwidth", "Not found")
j <- 1
for (i in Col.selection) {
O.table[1:7,j] <- quantile(S.table[(S.table$Algorithm == selected_value), i],
probs = c(0, 0.05, 0.25, 0.5, 0.75, 0.95, 1),
na.rm = TRUE)
O.table[8,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,i] < 1.1) &
(S.table[,i] > 0.9) &
!is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
!is.na(S.table[,i]),])
O.table[9,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0) &
is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0),])
j <- j + 1
}
O.table
#write.csv(C.table, paste0(path,"/S.table_accuracy.csv"))
selected_value <- 3
# Accuracy overview table
#Col.selection <- seq(11, 17, 3)
Col.selection <- seq(11, 20, 3)
O.table <- C.table[1:9, Col.selection]
rownames(O.table) <- c("Minimum", "5% percentile", "25% percentile",
"Median", "75% percentile", "95% percentile", "Maximum", "Bandwidth", "Not found")
j <- 1
for (i in Col.selection) {
O.table[1:7,j] <- quantile(S.table[(S.table$Algorithm == selected_value), i],
probs = c(0, 0.05, 0.25, 0.5, 0.75, 0.95, 1),
na.rm = TRUE)
O.table[8,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,i] < 1.1) &
(S.table[,i] > 0.9) &
!is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
!is.na(S.table[,i]),])
O.table[9,j] <- nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0) &
is.na(S.table[,i]),]) /
nrow(S.table[(S.table$Algorithm == selected_value) &
(S.table[,j] > 0),])
j <- j + 1
}
O.table
#write.csv(C.table, paste0(path,"/S.table_accuracy.csv"))
selection_1 <- R.table$Algorithm == 2
selection_1
selection_2 <- (R.table$Algorithm == 3) && (R.table$Channel.width * R.table$Channels <= 20)
selection_2
selection_2 <- (R.table$Algorithm == 3) && ((R.table$Channel.width * R.table$Channels) <= 20)
selection_2
R.table$Channel.width * R.table$Channels
A <- R.table$Channel.width * R.table$Channels
A <= 20
library(ggplot2)
library(gridExtra)
theme_set(theme_bw())
pre_selection_1 <- R.table$Channel.width * R.table$Channels
selection_1 <- (R.table$Algorithm == 3) && (pre_selection_1 >= 40)
pre_selection_2 <- R.table$Channel.width * R.table$Channels
selection_2 <- (R.table$Algorithm == 3) && (pre_selection_2 <= 20)
Dlot.1 <- rbind(data.frame(F.value = R.table[selection_1,]$F,
F.line = factor("same_line")),
data.frame(F.value = R.table[selection_1 & !is.na(R.table$F.next),]$F.next,
F.line = factor("next_line")))
library(ggplot2)
library(gridExtra)
theme_set(theme_bw())
pre_selection_1 <- R.table$Channel.width * R.table$Channels
selection_1 <- (R.table$Algorithm == 3) & (pre_selection_1 >= 40)
pre_selection_2 <- R.table$Channel.width * R.table$Channels
selection_2 <- (R.table$Algorithm == 3) & (pre_selection_2 <= 20)
Dlot.1 <- rbind(data.frame(F.value = R.table[selection_1,]$F,
F.line = factor("same_line")),
data.frame(F.value = R.table[selection_1 & !is.na(R.table$F.next),]$F.next,
F.line = factor("next_line")))
Dlot.1$F.value <- log10(Dlot.1$F.value)
Plot.1 <- ggplot(Dlot.1, aes(x = F.value, color = F.line)) +
geom_density(size=1) + ylim(0, 0.7) +
scale_x_continuous(limits = c(-2,7), breaks = c(-1,0,1,2,3,4,5,6),
labels = c("0.1","1", "10","100","10^3","10^4","10^5","10^6")) +
labs(y = "Event Density per Order of 10", x = "F-value") +
ggtitle("DE") +
theme(legend.position = "none",
axis.title = element_text(size=16),
axis.text = element_text(size=14),
plot.title = element_text(size=18, face="bold"))
###################################################
Dlot.2 <- rbind(data.frame(F.value = R.table[selection_2,]$F,
F.line = factor("same_line_weighted")),
data.frame(F.value = R.table[selection_2 & !is.na(R.table$F.next),]$F.next,
F.line = factor("next_line_weighted")))
Dlot.2$F.value <- log10(Dlot.2$F.value)
Plot.2 <- ggplot(Dlot.2, aes(x = F.value, color = F.line)) +
geom_density(size=1) + ylim(0, 0.7) +
scale_x_continuous(limits = c(-2,7), breaks = c(-1,0,1,2,3,4,5,6),
labels = c("0.1","1", "10","100","10^3","10^4","10^5","10^6")) +
labs(x = "F-value") +
ggtitle("DE+LM") +
theme(legend.position = "none",
axis.title = element_text(size=16), axis.title.y = element_blank(),
axis.ticks.y = element_blank(), axis.text.y = element_blank(),
axis.text.x = element_text(size=14),
plot.title = element_text(size=18, face="bold"))
###################################################
lay <- rbind(c(rep(1,10),rep(2,9)))
grid.arrange(Plot.1, Plot.2, layout_matrix = lay)
# How many values were used?
print(paste0("F with DE only: ", nrow(R.table[selection_1,])))
print(paste0("F.next with DE only: ", nrow(R.table[selection_1,]) & !is.na(R.table$F.next),])))
library(ggplot2)
library(gridExtra)
theme_set(theme_bw())
pre_selection_1 <- R.table$Channel.width * R.table$Channels
selection_1 <- (R.table$Algorithm == 3) & (pre_selection_1 >= 40)
pre_selection_2 <- R.table$Channel.width * R.table$Channels
selection_2 <- (R.table$Algorithm == 3) & (pre_selection_2 <= 20)
Dlot.1 <- rbind(data.frame(F.value = R.table[selection_1,]$F,
F.line = factor("same_line")),
data.frame(F.value = R.table[selection_1 & !is.na(R.table$F.next),]$F.next,
F.line = factor("next_line")))
Dlot.1$F.value <- log10(Dlot.1$F.value)
Plot.1 <- ggplot(Dlot.1, aes(x = F.value, color = F.line)) +
geom_density(size=1) + ylim(0, 0.7) +
scale_x_continuous(limits = c(-2,7), breaks = c(-1,0,1,2,3,4,5,6),
labels = c("0.1","1", "10","100","10^3","10^4","10^5","10^6")) +
labs(y = "Event Density per Order of 10", x = "F-value") +
ggtitle("DE") +
theme(legend.position = "none",
axis.title = element_text(size=16),
axis.text = element_text(size=14),
plot.title = element_text(size=18, face="bold"))
###################################################
Dlot.2 <- rbind(data.frame(F.value = R.table[selection_2,]$F,
F.line = factor("same_line_weighted")),
data.frame(F.value = R.table[selection_2 & !is.na(R.table$F.next),]$F.next,
F.line = factor("next_line_weighted")))
Dlot.2$F.value <- log10(Dlot.2$F.value)
Plot.2 <- ggplot(Dlot.2, aes(x = F.value, color = F.line)) +
geom_density(size=1) + ylim(0, 0.7) +
scale_x_continuous(limits = c(-2,7), breaks = c(-1,0,1,2,3,4,5,6),
labels = c("0.1","1", "10","100","10^3","10^4","10^5","10^6")) +
labs(x = "F-value") +
ggtitle("DE+LM") +
theme(legend.position = "none",
axis.title = element_text(size=16), axis.title.y = element_blank(),
axis.ticks.y = element_blank(), axis.text.y = element_blank(),
axis.text.x = element_text(size=14),
plot.title = element_text(size=18, face="bold"))
###################################################
lay <- rbind(c(rep(1,10),rep(2,9)))
grid.arrange(Plot.1, Plot.2, layout_matrix = lay)
# How many values were used?
print(paste0("F with DE only: ", nrow(R.table[selection_1,])))
print(paste0("F.next with DE only: ", nrow(R.table[selection_1,] & !is.na(R.table$F.next),])))
library(ggplot2)
library(gridExtra)
theme_set(theme_bw())
pre_selection_1 <- R.table$Channel.width * R.table$Channels
selection_1 <- (R.table$Algorithm == 3) & (pre_selection_1 >= 40)
pre_selection_2 <- R.table$Channel.width * R.table$Channels
selection_2 <- (R.table$Algorithm == 3) & (pre_selection_2 <= 20)
Dlot.1 <- rbind(data.frame(F.value = R.table[selection_1,]$F,
F.line = factor("same_line")),
data.frame(F.value = R.table[selection_1 & !is.na(R.table$F.next),]$F.next,
F.line = factor("next_line")))
Dlot.1$F.value <- log10(Dlot.1$F.value)
Plot.1 <- ggplot(Dlot.1, aes(x = F.value, color = F.line)) +
geom_density(size=1) + ylim(0, 0.7) +
scale_x_continuous(limits = c(-2,7), breaks = c(-1,0,1,2,3,4,5,6),
labels = c("0.1","1", "10","100","10^3","10^4","10^5","10^6")) +
labs(y = "Event Density per Order of 10", x = "F-value") +
ggtitle("DE") +
theme(legend.position = "none",
axis.title = element_text(size=16),
axis.text = element_text(size=14),
plot.title = element_text(size=18, face="bold"))
###################################################
Dlot.2 <- rbind(data.frame(F.value = R.table[selection_2,]$F,
F.line = factor("same_line_weighted")),
data.frame(F.value = R.table[selection_2 & !is.na(R.table$F.next),]$F.next,
F.line = factor("next_line_weighted")))
Dlot.2$F.value <- log10(Dlot.2$F.value)
Plot.2 <- ggplot(Dlot.2, aes(x = F.value, color = F.line)) +
geom_density(size=1) + ylim(0, 0.7) +
scale_x_continuous(limits = c(-2,7), breaks = c(-1,0,1,2,3,4,5,6),
labels = c("0.1","1", "10","100","10^3","10^4","10^5","10^6")) +
labs(x = "F-value") +
ggtitle("DE+LM") +
theme(legend.position = "none",
axis.title = element_text(size=16), axis.title.y = element_blank(),
axis.ticks.y = element_blank(), axis.text.y = element_blank(),
axis.text.x = element_text(size=14),
plot.title = element_text(size=18, face="bold"))
###################################################
lay <- rbind(c(rep(1,10),rep(2,9)))
grid.arrange(Plot.1, Plot.2, layout_matrix = lay)
# How many values were used?
print(paste0("F with DE only: ", nrow(R.table[selection_1,])))
print(paste0("F.next with DE only: ", nrow(R.table[selection_1 & !is.na(R.table$F.next),])))
print(paste0("F with LM: ", nrow(R.table[selection_2,])))
print(paste0("F.next  with LM: ", nrow(R.table[selection_2 & !is.na(R.table$F.next),])))
library(ggplot2)
library(gridExtra)
theme_set(theme_bw())
pre_selection_1 <- R.table$Channel.width * R.table$Channels
selection_1 <- (R.table$Algorithm == 3) & (pre_selection_1 >= 40)
pre_selection_2 <- R.table$Channel.width * R.table$Channels
selection_2 <- (R.table$Algorithm == 3) & (pre_selection_2 <= 20)
Dlot.1 <- rbind(data.frame(F.value = R.table[selection_1,]$F,
F.line = factor("same_line")),
data.frame(F.value = R.table[selection_1,]$F.next,
F.line = factor("next_line")))
Dlot.1$F.value <- log10(Dlot.1$F.value)
Plot.1 <- ggplot(Dlot.1, aes(x = F.value, color = F.line)) +
geom_density(size=1) + ylim(0, 0.7) +
scale_x_continuous(limits = c(-2,7), breaks = c(-1,0,1,2,3,4,5,6),
labels = c("0.1","1", "10","100","10^3","10^4","10^5","10^6")) +
labs(y = "Event Density per Order of 10", x = "F-value") +
ggtitle("DE") +
theme(legend.position = "none",
axis.title = element_text(size=16),
axis.text = element_text(size=14),
plot.title = element_text(size=18, face="bold"))
###################################################
Dlot.2 <- rbind(data.frame(F.value = R.table[selection_2,]$F,
F.line = factor("same_line_weighted")),
data.frame(F.value = R.table[selection_2,]$F.next,
F.line = factor("next_line_weighted")))
Dlot.2$F.value <- log10(Dlot.2$F.value)
Plot.2 <- ggplot(Dlot.2, aes(x = F.value, color = F.line)) +
geom_density(size=1) + ylim(0, 0.7) +
scale_x_continuous(limits = c(-2,7), breaks = c(-1,0,1,2,3,4,5,6),
labels = c("0.1","1", "10","100","10^3","10^4","10^5","10^6")) +
labs(x = "F-value") +
ggtitle("DE+LM") +
theme(legend.position = "none",
axis.title = element_text(size=16), axis.title.y = element_blank(),
axis.ticks.y = element_blank(), axis.text.y = element_blank(),
axis.text.x = element_text(size=14),
plot.title = element_text(size=18, face="bold"))
###################################################
lay <- rbind(c(rep(1,10),rep(2,9)))
grid.arrange(Plot.1, Plot.2, layout_matrix = lay)
# How many values were used?
print(paste0("F with DE only: ", nrow(R.table[selection_1,])))
print(paste0("F.next with DE only: ", nrow(R.table[selection_1 & !is.na(R.table$F.next),])))
print(paste0("F with LM: ", nrow(R.table[selection_2,])))
print(paste0("F.next  with LM: ", nrow(R.table[selection_2 & !is.na(R.table$F.next),])))
# Calc photon energy: E = h*v  [W*s^2 * s^-1 = W*s = J]
E <-6.62606957e-34 * 299792458 * 10^9 / stimulation.wavelength
# Calc photon flux of stimulation light: Flux = I / E  [W/cm^2 / W*s = 1/s*cm^2]
Flux <- stimulation.intensity / (E * 1000)
Flux <- 30 / (6.62606957e-34 * (299792458 * 10^9 / 480) * 1000)
Flux * 2.6e-17
Flux <- 31 / (6.62606957e-34 * (299792458 * 10^9 / 480) * 1000)
Flux * 2.6e-17
Flux <- 30 / (6.62606957e-34 * (299792458 * 10^9 / 480) * 1000)
Flux * 4.28e-18
Flux * 1.09e-18
Flux * 3.04e-19
# ToDo, use more accurate lambda values
#lambda <- c(Fast = 2, Medium = 0.5, Slow1 = 0.1, Slow2 = 0.02)
# Calculated from Durcan & Duller, assuming an stimulation intensity of 30 mW/cm² (typical for a Risö OSL/TL DA-15)
lambda <- c(Fast = 1.9, Medium = 0.3, Slow1 = 0.08, Slow2 = 0.02)
X <- 1:length(lambda)
#algorithm_names <- c("numOSL","DE","DE+LM")
algorithm_names <- c("DE","DE+LM")
V.list <- list(n.Fast = c(0, 1000, 3000, 10000, 30000),
n.Medium = c(0, 1000, 3000, 10000),
n.Slow1 = c(0, 3000, 10000, 30000),
n.Slow2 = c(10000, 30000, 100000),
Background = c(0),
Channels = c(100, 200, 400),
Channel.width = c(0.1, 0.2, 0.5),
Additions = c(100, 400),
Algorithm = c(0, 1))
# from earlier simulations, we showed that the impact of uncorrected background signals,
# as well as from the number of additions is insignificant
# it was also shown, that unweighted fitting (Chi² = RSS) leads to more precise
# fast and medium component decay rates
V.max <- NULL
for (i in 1:length(V.list)) {
V.max <- c(V.max, length(V.list[[i]]))
}
N <- prod(V.max)
cat("Number of scenarios:", N,"\n")
source('C:/Users/mitte/Desktop/R/OSLdecomposition/R/fit_OSLcurve.R', encoding = 'UTF-8')
